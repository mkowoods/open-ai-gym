{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwoods/Developer/open-ai-gym/venv/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:33:45,777] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "path_to_recording = './tmp/CartPole-v0-gradient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DQN():\n",
    "    \"\"\"\n",
    "    4 layer(2 hidden layer) network\n",
    "    input: state array\n",
    "    output: estimated q_values(future reward for choosing that action)\n",
    "    \"\"\"\n",
    "\n",
    "    state = tf.placeholder(dtype = tf.float32, shape = (None, 4))\n",
    "    Q_actuals = tf.placeholder(dtype=tf.float32, shape = (None, 2))\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal([4, 10], stddev = 0.1))\n",
    "    b1 = tf.Variable(tf.truncated_normal([10], stddev = 0.1))\n",
    "    h1 = tf.nn.tanh(tf.matmul(state, w1) + b1)\n",
    "\n",
    "    w2 = tf.Variable(tf.truncated_normal([10, 10], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.truncated_normal([10], stddev=0.1))\n",
    "    h2 = tf.nn.tanh(tf.matmul(h1, w2) + b2)\n",
    "\n",
    "    w3 = tf.Variable(tf.random_normal([10, 2]))\n",
    "    b3 = tf.Variable(tf.zeros([2]))\n",
    "    Q_est = tf.tanh(tf.matmul(h2, w3) + b3)\n",
    "\n",
    "    loss = tf.nn.l2_loss(Q_est - Q_actuals)\n",
    "    optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "    return optimizer, state, Q_actuals, Q_est, loss, w1, w2, w3\n",
    "\n",
    "\n",
    "class ExperienceReplay:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "        self.max_size = 5000\n",
    "        self.batch_size = 250\n",
    "        \n",
    "    def add_observation(self, step, obs, action, reward, is_done, new_obs, future_reward):\n",
    "        if len(memory) > self.max_size:\n",
    "            self.memory.pop()\n",
    "        \n",
    "        self.memory.append((step, obs, action, reward, is_done, new_obs, future_reward))\n",
    "    \n",
    "    def get_mini_batch(self):\n",
    "        return np.random.choice(self.memory, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "dqn_opt, dqn_state, dqn_q_actuals, dqn_q_est, dqn_loss, w1, w2, w3 = DQN()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "TOTAL_NUMBER_OF_TRAINING_EPISODES = 0\n",
    "dqn_loss_hist = []\n",
    "reward_hist = []\n",
    "steps_hist = []\n",
    "max_prob_eps_mean = []\n",
    "max_prob_eps_std = []\n",
    "mean_advantage = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.58397526  0.41602477]\n",
      "1 [ 0.57893062  0.42106941]\n",
      "1 [ 0.58393383  0.41606623]\n",
      "1 [ 0.58886158  0.41113847]\n",
      "0 [ 0.59369504  0.4063049 ]\n",
      "0 [ 0.58897781  0.41102222]\n",
      "0 [ 0.58408457  0.41591537]\n",
      "1 [ 0.57904118  0.42095888]\n",
      "1 [ 0.58401978  0.41598022]\n",
      "1 [ 0.58891571  0.41108435]\n",
      "0 [ 0.59370989  0.40629011]\n",
      "1 [ 0.58899695  0.41100302]\n",
      "1 [ 0.59378433  0.40621567]\n",
      "0 [ 0.59845114  0.40154886]\n",
      "0 [ 0.59395075  0.40604928]\n",
      "0 [ 0.58925498  0.41074502]\n",
      "0 [ 0.5843842   0.41561577]\n",
      "0 [ 0.5793584  0.4206416]\n",
      "0 [ 0.57419723  0.42580274]\n",
      "0 [ 0.5689202  0.4310798]\n",
      "1 [ 0.5635466   0.43645337]\n",
      "0 [ 0.56840211  0.43159789]\n",
      "0 [ 0.56296897  0.437031  ]\n",
      "0 [ 0.55745757  0.44254246]\n",
      "0 [ 0.55188936  0.44811064]\n",
      "1 [ 0.54628664  0.45371336]\n",
      "0 [ 0.5507918   0.44920817]\n",
      "0 [ 0.54510796  0.45489204]\n",
      "1 [ 0.53942376  0.46057624]\n",
      "0 [ 0.54373538  0.45626464]\n",
      "1 [ 0.53799266  0.46200734]\n",
      "0 [ 0.54227424  0.45772573]\n",
      "0 [ 0.53650147  0.4634985 ]\n",
      "1 [ 0.53079313  0.46920681]\n",
      "1 [ 0.53487241  0.46512762]\n",
      "0.0 0 1.0 False 1.41573940686\n",
      "1.0 1 1.0 False 1.35804216424\n",
      "2.0 1 1.0 False 1.29856047081\n",
      "3.0 1 1.0 False 1.23723913739\n",
      "4.0 0 1.0 False 1.17402126788\n",
      "5.0 0 1.0 False 1.10884820653\n",
      "6.0 0 1.0 False 1.04165948348\n",
      "7.0 1 1.0 False 0.972392758697\n",
      "8.0 1 1.0 False 0.900983764072\n",
      "9.0 1 1.0 False 0.82736624384\n",
      "10.0 0 1.0 False 0.751471893085\n",
      "11.0 1 1.0 False 0.673230294369\n",
      "12.0 1 1.0 False 0.592568852394\n",
      "13.0 0 1.0 False 0.509412726646\n",
      "14.0 0 1.0 False 0.423684761957\n",
      "15.0 0 1.0 False 0.335305416918\n",
      "16.0 0 1.0 False 0.244192690072\n",
      "17.0 0 1.0 False 0.15026204384\n",
      "18.0 0 1.0 False 0.0534263260753\n",
      "19.0 0 1.0 False -0.0464043107959\n",
      "20.0 1 1.0 False -0.149322493137\n",
      "21.0 0 1.0 False -0.255423712046\n",
      "22.0 0 1.0 False -0.364806411952\n",
      "23.0 0 1.0 False -0.477572081958\n",
      "24.0 0 1.0 False -0.593825350005\n",
      "25.0 1 1.0 False -0.713674079951\n",
      "26.0 0 1.0 False -0.837229471648\n",
      "27.0 0 1.0 False -0.964606164119\n",
      "28.0 1 1.0 False -1.09592234192\n",
      "29.0 0 1.0 False -1.23129984482\n",
      "30.0 1 1.0 False -1.37086428079\n",
      "31.0 0 1.0 False -1.51474514261\n",
      "32.0 0 1.0 False -1.663075928\n",
      "33.0 1 1.0 False -1.81599426345\n",
      "34.0 1 1.0 True -1.97364203196\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1\n",
    "gamma = 0.97\n",
    "\n",
    "softmax = lambda np_arr : np.exp(np_arr)/np.sum(np.exp(np_arr))\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0.0\n",
    "    episode_history = []\n",
    "    states = []\n",
    "    max_prob = []\n",
    "    while True:\n",
    "        \n",
    "        q_est = sess.run(dqn_q_est, feed_dict={dqn_state: np.expand_dims(obs, axis=0)})\n",
    "        q_est = q_est[0] #unpack the values\n",
    "\n",
    "        #need to define a better exploration_function\n",
    "        q_est_softmax = softmax(q_est)\n",
    "        max_prob.append(q_est_softmax.max())\n",
    "        action = np.random.choice([0, 1], p = q_est_softmax)\n",
    "        print action, q_est_softmax\n",
    "        next_obs, reward, is_done, _ = env.step(action)\n",
    "        \n",
    "        unk_future_reward = None\n",
    "        episode_history.append([total_steps, obs, action, reward, is_done, next_obs, unk_future_reward]) \n",
    "        total_reward += reward\n",
    "        total_steps += 1.0\n",
    "        obs = next_obs\n",
    "        if is_done:\n",
    "            break\n",
    "    \n",
    "    future_rewards = []\n",
    "    cumm_reward = 0.0\n",
    "    for idx, trans in enumerate(episode_history[::-1]): \n",
    "        total_steps, obs, action, reward, is_done, next_obs, future_reward = trans\n",
    "        cumm_reward += (gamma**idx) * reward\n",
    "        future_rewards.append(cumm_reward)\n",
    "    future_rewards = np.array(future_rewards[::-1]) #go through the array in reverse and then flip it back at then end\n",
    "    fr_mu, fr_sigma = future_rewards.mean(), future_rewards.std()\n",
    "    future_rewards = (future_rewards - fr_mu)/fr_sigma\n",
    "    \n",
    "    for trans, future_reward in zip(episode_history, future_rewards):\n",
    "        trans[-1] = future_reward\n",
    "        print trans[0], trans[2], trans[3], trans[4], trans[-1]\n",
    "        \n",
    "    \n",
    "    #load monitoring dbs\n",
    "    max_prob_eps_mean.append(np.array(max_prob).mean())\n",
    "    max_prob_eps_std.append(np.array(max_prob).std())\n",
    "    reward_hist.append( total_reward )\n",
    "    steps_hist.append( total_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01165618,  0.02830083, -0.03131809, -0.00572727]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.reshape(1, obs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01165618  0.02830083 -0.03131809 -0.00572727]]\n",
      "[[-0.01165618]\n",
      " [ 0.02830083]\n",
      " [-0.03131809]\n",
      " [-0.00572727]]\n"
     ]
    }
   ],
   "source": [
    "print np.expand_dims(obs, axis=0)\n",
    "print np.expand_dims(obs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59836054,  0.48353952]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52867377,  0.47132623]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = lambda np_arr : np.exp(np_arr)/np.sum(np.exp(np_arr))\n",
    "softmax(q_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47258"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ np.random.choice([0, 1], p = softmax(q_est[0])) for _ in range(100000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [1, 2, 3, [1, 2, 3, inf]]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2, 3, _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}